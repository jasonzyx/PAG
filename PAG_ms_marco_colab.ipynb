{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b2b3b2",
   "metadata": {},
   "source": [
    "# PAG Retrieval on MS MARCO Sample\n",
    "This notebook demonstrates how to run the PAG model on a small sample of the MS MARCO dataset. It follows the instructions from the repository and downloads a pre-trained model along with the necessary mapping files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd9625",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "Install dependencies and clone the PAG repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/HansiZeng/PAG.git\n",
    "%cd PAG\n",
    "!pip install -r requirements.txt\n",
    "!pip install torch==1.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install faiss-gpu==1.7.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a5bbde",
   "metadata": {},
   "source": [
    "## 2. Download Pre-trained Model and Mapping Files\n",
    "The following commands fetch a pre-trained checkpoint and the document ID mappings required for inference. The files are hosted on Google Drive in the [`PAG-data`](https://drive.google.com/drive/folders/1q8FeHQ6nxPYpl1Thqw8mS-2ndzf7VZ9y) folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53948d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, zipfile\n",
    "!pip install gdown\n",
    "os.makedirs('data', exist_ok=True)\n",
    "%cd data\n",
    "# Download model checkpoint (replace file id with actual id)\n",
    "!gdown 1A7VYJZkxxxxxx -O pag_model.zip\n",
    "with zipfile.ZipFile('pag_model.zip', 'r') as zf:\n",
    "    zf.extractall()\n",
    "# Download docid_to_tokenids files (replace file id with actual id)\n",
    "!gdown 1B8xxxxxxx -O docids.zip\n",
    "with zipfile.ZipFile('docids.zip', 'r') as zf:\n",
    "    zf.extractall()\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b2d6a",
   "metadata": {},
   "source": [
    "## 3. Prepare a Small MS MARCO Sample\n",
    "We use the HuggingFace `datasets` library to fetch a small subset of MS MARCO passages and queries. This subset will be used to illustrate the retrieval pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d95f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json, os\n",
    "\n",
    "sample_size = 1000\n",
    "queries_size = 10\n",
    "\n",
    "passages = load_dataset('ms_marco', 'v1.1', split=f'passages[:{sample_size}]')\n",
    "queries = load_dataset('ms_marco', 'v1.1', split=f'queries[:{queries_size}]')\n",
    "\n",
    "os.makedirs('data/msmarco-sample', exist_ok=True)\n",
    "with open('data/msmarco-sample/full_collection', 'w') as f:\n",
    "    for p in passages:\n",
    "        f.write(f\"{p['pid']}\t{p['passage']}\n",
    "\")\n",
    "\n",
    "os.makedirs('data/msmarco-sample/sample_queries', exist_ok=True)\n",
    "with open('data/msmarco-sample/sample_queries/queries', 'w') as f:\n",
    "    for q in queries:\n",
    "        f.write(f\"{q['qid']}\t{q['query']}\n",
    "\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790246b",
   "metadata": {},
   "source": [
    "## 4. Run PAG Inference\n",
    "We modify the evaluation script to point to our sample dataset and execute it. The script will output retrieval results and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e2867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "script_path = pathlib.Path('full_scripts/full_lexical_ripor_evaluate.sh')\n",
    "text = script_path.read_text()\n",
    "text = text.replace('data/msmarco-full', 'data/msmarco-sample')\n",
    "script_path.write_text(text)\n",
    "!bash full_scripts/full_lexical_ripor_evaluate.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4602db80",
   "metadata": {},
   "source": [
    "## 5. Inspect Retrieval Outputs\n",
    "The retrieval results are stored under the model directory's output folder. This cell prints the first few lines of the run file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cea2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json\n",
    "run_files = glob.glob('data/experiments-full-lexical-ripor/**/*.json', recursive=True)\n",
    "for path in run_files[:5]:\n",
    "    print(path)\n",
    "    with open(path) as f:\n",
    "        print(json.dumps(json.load(f)[:5], indent=2))\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
