{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac7282d",
   "metadata": {},
   "source": [
    "# PAG End-to-End on MS MARCO Sample\n",
    "This Colab notebook demonstrates environment setup, data preparation, model fine-tuning, and evaluation of the PAG model on a small MS MARCO subset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b375b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "Install dependencies and clone the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd93c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/HansiZeng/PAG.git\n",
    "%cd PAG\n",
    "!pip install -r requirements.txt\n",
    "!pip install torch==1.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install faiss-gpu==1.7.2\n",
    "!pip install gdown\n",
    "!pip install --upgrade pyarrow nbformat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e87a2",
   "metadata": {},
   "source": [
    "## 2. Download Pre-trained Model and Mapping Files\n",
    "Fetch a pre-trained checkpoint and document ID mappings from Google Drive (replace the file IDs with the correct ones from the PAG-data folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, zipfile\n",
    "os.makedirs('data', exist_ok=True)\n",
    "%cd data\n",
    "# Download model checkpoint\n",
    "!gdown 1A7VYJZkxxxxxx -O pag_model.zip\n",
    "with zipfile.ZipFile('pag_model.zip', 'r') as zf: zf.extractall()\n",
    "# Download docid_to_tokenids files\n",
    "!gdown 1B8xxxxxxx -O docids.zip\n",
    "with zipfile.ZipFile('docids.zip', 'r') as zf: zf.extractall()\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ae4850",
   "metadata": {},
   "source": [
    "## 3. Prepare a Small MS MARCO Sample\n",
    "Load a subset of MS MARCO passages and queries, build training pairs, and write them in the format expected by the training scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83289ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os, random, ujson\n",
    "\n",
    "passage_count = 1000\n",
    "query_count = 20\n",
    "\n",
    "passages = load_dataset('ms_marco', 'v1.1', split=f'passages[:{passage_count}]')\n",
    "queries = load_dataset('ms_marco', 'v1.1', split=f'queries[:{query_count}]')\n",
    "qrels = load_dataset('ms_marco', 'v1.1', split=f'qrels[:{query_count}]')\n",
    "\n",
    "os.makedirs('data/msmarco-sample/full_collection', exist_ok=True)\n",
    "with open('data/msmarco-sample/full_collection/raw.tsv','w') as f:\n",
    "    for p in passages:\n",
    "        f.write(f\"{p['pid']}\\t{p['passage']}\\n\")\n",
    "\n",
    "os.makedirs('data/msmarco-sample/train_queries', exist_ok=True)\n",
    "with open('data/msmarco-sample/train_queries/raw.tsv','w') as f:\n",
    "    for q in queries:\n",
    "        f.write(f\"{q['qid']}\\t{q['query']}\\n\")\n",
    "\n",
    "# Build qrels dict and training pairs\n",
    "qid_to_pos = {}\n",
    "for qr in qrels:\n",
    "    qid_to_pos.setdefault(str(qr['query_id']), []).append(str(qr['passage_id']))\n",
    "all_docids = [str(p['pid']) for p in passages]\n",
    "with open('data/msmarco-sample/train_pairs.jsonl','w') as f:\n",
    "    for q in queries:\n",
    "        qid = str(q['qid'])\n",
    "        if qid not in qid_to_pos:\n",
    "            continue\n",
    "        pos = qid_to_pos[qid][0]\n",
    "        neg = random.choice([d for d in all_docids if d != pos])\n",
    "        f.write(ujson.dumps({'qid': qid, 'docids': [pos, neg], 'scores': [1.0, 0.0]}) + '\\n')\n",
    "\n",
    "# Save qrels for evaluation\n",
    "qrel_dict = {}\n",
    "for qid, docs in qid_to_pos.items():\n",
    "    qrel_dict[qid] = {d: 1 for d in docs}\n",
    "with open('data/msmarco-sample/qrels.json','w') as f:\n",
    "    ujson.dump(qrel_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178cbe94",
   "metadata": {},
   "source": [
    "## 4. Fine-tune PAG on the Sample\n",
    "Use the prepared pairs to fine-tune the pre-trained PAG model for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a26657",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m t5_pretrainer.main   --epochs=1   --run_name=sample_run   --learning_rate=5e-4   --loss_type=margin_mse   --model_name_or_path=t5-base   --model_type=lexical_ripor   --teacher_score_path=data/msmarco-sample/train_pairs.jsonl   --output_dir=data/experiments-sample   --task_names='[\"rank\",\"lexical_rank\"]'   --collection_path=data/msmarco-sample/full_collection   --queries_path=data/msmarco-sample/train_queries   --pretrained_path=data/experiments-full-lexical-ripor/lexical_ripor_direct_lng_knp_seq2seq_1/checkpoint   --smt_docid_to_smtid_path=data/experiments-full-lexical-ripor/t5-full-dense-1-5e-4-12l/aq_smtid/docid_to_tokenids.json   --lex_docid_to_smtid_path=data/experiments-splade/t5-splade-0-12l/top_bow/docid_to_tokenids.json   --per_device_train_batch_size=2   --max_length=64   --use_fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f7f30",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Fine-tuned Model\n",
    "Run constrained beam search on the sample queries and compute retrieval metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04568f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m t5_pretrainer.evaluate   --pretrained_path=data/experiments-sample/sample_run/checkpoint   --out_dir=data/experiments-sample/output   --task=constrained_beam_search_for_qid_rankdata   --docid_to_tokenids_path=data/experiments-full-lexical-ripor/t5-full-dense-1-5e-4-12l/aq_smtid/docid_to_tokenids.json   --q_collection_paths='[\"data/msmarco-sample/train_queries/\"]'   --batch_size=1   --max_new_token_for_docid=8   --topk=10\n",
    "!python -m t5_pretrainer.evaluate   --task=constrained_beam_search_for_qid_rankdata_2   --out_dir=data/experiments-sample/output   --q_collection_paths='[\"data/msmarco-sample/train_queries/\"]'   --eval_qrel_path='[\"data/msmarco-sample/qrels.json\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32650fe3",
   "metadata": {},
   "source": [
    "## 6. Inspect Retrieval Outputs\n",
    "Display a snippet of the generated run file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json\n",
    "run_files = glob.glob('data/experiments-sample/output/**/*.json', recursive=True)\n",
    "for path in run_files[:5]:\n",
    "    print(path)\n",
    "    with open(path) as f:\n",
    "        print(json.dumps(json.load(f)[:5], indent=2))\n",
    "    break"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
